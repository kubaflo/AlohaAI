{
  "moduleId": "04-content-safety",
  "passingScore": 70,
  "questions": [
    {
      "id": "q1",
      "type": "MultipleChoice",
      "question": "What is C2PA used for?",
      "options": [
        "Compressing images",
        "Establishing content provenance and authenticity",
        "Training LLMs",
        "Encrypting prompts"
      ],
      "correctIndex": 1,
      "explanation": "C2PA (Coalition for Content Provenance and Authenticity) creates a standard for embedding verifiable metadata about how content was created.",
      "xp": 5
    },
    {
      "id": "q2",
      "type": "TrueFalse",
      "question": "Invisible watermarks embedded in AI-generated images can survive common editing operations like cropping and compression.",
      "options": [
        "True",
        "False"
      ],
      "correctIndex": 0,
      "explanation": "Modern watermarking techniques are designed to be robust against cropping, compression, screenshots, and other common transformations.",
      "xp": 5
    },
    {
      "id": "q3",
      "type": "MultipleChoice",
      "question": "A moderation pipeline for generated images typically:",
      "options": [
        "Only checks text prompts",
        "Scans both the input prompt and the generated output for policy violations",
        "Only checks the final image",
        "Only runs during training"
      ],
      "correctIndex": 1,
      "explanation": "Effective moderation checks both the requesting prompt (for intent) and the generated output (for actual content) against safety policies.",
      "xp": 5
    }
  ]
}